---
title: "[컴퓨터 구조론 이론] 메모리와 캐시 메모리"
tags:
  - cs
image: ./assets/banner.png
date: 2026-02-24 06:18:27
series: 컴퓨터 구조론 이론
draft: false
---

![banner](./assets/banner.png)

> 본 포스팅은 인프런의 [개발자를 위한 컴퓨터공학 1: 혼자 공부하는 컴퓨터구조 + 운영체제](https://inf.run/6vJaw)를 참조하여 작성한 글입니다.

## RAM의 특징과 종류

이번에는 우리가 지금까지 메모리로 지칭했던 저장장치인 RAM을 조금 더 자세히 알아보도록 하겠다. RAM 용량이 컴퓨터 성능에 어떤 영향을 미치는지 그리고 DRAM, SRAM, SDRAM, DDR SDRAM은 무엇이고 어떤 특징을 가지는지 가볍게 살펴보자.

### RAM의 특징

RAM에는 실행할 프로그램의 명령어와 데이터가 저장된다. 여기서 중요한 점은 전원을 끄면 RAM에 저장된 명령어와 데이터가 모두 날라간다는 점이다. 이렇게 전원을 끄면 저장된 내용이 사라지는 저장장치를 **휘발성 저장장치**라고 한다. 반면 전원이 꺼져도 저장된 내용이 유지되는 저장장치는 **비휘발성 저장장치**라고 한다. HDD나 SSD 메모리와 같은 보조기억 장치가 대표적인 비휘발성 저장장치이다.

### RAM의 용량과 성능

그러면 이런 생각으 문득 들 수 있다. RAM이 크면 무엇이 좋을까? RAM의 용량은 컴퓨터 성능에 어떤 영향을 미칠까? 예를 들어 RAM이 하나의 프로그램밖에 저장을 할 수 없다라고 해보자. 그러면 다른 프로그램을 실행시킬때 해당 프로그램을 백업하고 다른 프로그램 실행시키고를 반복해야 하는데 동시 실행 성능이 떨어지게 된다. 반면 충분하게 RAM에 여러 프로그램을 실행시킬 수 있다라면 그 만큼 동시 실행 성능이 올라갈 것이다.

### RAM의 종류

다음으로 RAM의 종류에 대해 살펴보도록 하겠다.

**DRAM**은 Dynamin RAM의 준말이다. Dynamic은 영어로 '동적의'를 의미하는데 이는 저장된 데이터가 동적으로 사라지는 RAM을 말한다. 즉, DRAM은 시간이 지나면 저장된 데이터가 점차 사라지는 RAM이기에 데이터 소멸을 막기 위해 일정 주기로 데이터를 재활성화해야 한다. 그러면 이런 DRAM은 어디서 사용될까? 뭔가 듣기만 하면 점차 저장된 데이터가 소멸되니 아무데도 사용되지 않을 것 같다. 하지만 DRAM은 일반적으로 사용되는 메모리이다. 왜냐하면 상대적으로 소비전력이 낮고 저렴하고 집적도가 높아 대용량으로 설계하기 용이하기 때문이다.

다음으로 **SRAM**을 살펴보자. SRAM은 Static RAM의 준말이다. Static은 영어로 '정적의'를 의미하는데 이는 저장된 데이터가 변하지 않는 RAM이라는 의미이다. SRAM은 DRAM보다 일반적으로 더 빠르며 캐시 메모리에 사용된다. SRAM은 상대적으로 소비전력이 높고 가격이 높고 집적도가 낮아 대용량으로 설계하기 힘들다.

다음으로 **SDRAM**이다. SDRAM은 특별한 혹은 발전된 형태의 DRAM이다. 또한, 클럭신호와 동기화된 DRAM이다. 클럭신호와 동기화되었다는 말은 클럭 타이밍에 맞춰 CPU와 정보를 주고 받을 수 있음을 의미한다. 즉, SDRAM은 클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고받을 수 있는 DRAM이다.

다음으로 **DDR SDRAM**이다. DDR SDRAM은 최근 가장 흔히 사용되는 RAM이다. DDR SDRAM은 대역폭을 넓혀 속도를 빠르게 만든 SDRAM이다. 여기서 대역폭이란 데이터를 주고받는 길의 너비를 의미한다.

## 메모리의 주소 공간

지금까지 메모리에 저장된 정보의 위치는 주소로 나타낼 수 있다라고 말씀드렸다. 사실 주소에는 2가지 종류가 존재한다. 바로 물리 주소와 논리 주소이다. 물리 주소는 메모리 하드웨어가 사용하는 주소이고, 논리 주소는 CPU와 실행 중인 프로그램이 사용하는 주소를 말한다.

그러면 왜 논리 주소와 물리 주소로 주소 공간을 나눈 이유는 무엇일까? 또한 논리 주소를 물리 주소로 변환하는 방법은 무엇일까? 이것에 대해 한번 알아보도록 하자.

### 물리 주소와 논리 주소

CPU와 실행 중인 프로그램은 현재 메모리 몇번에 실행되는지 알 수 있을까? 정답은 모른다. 왜냐하면 메모리에 저장된 값들은 시시각각 변하기 때문이다. 보통 새롭게 실행되는 프로그램은 새롭게 메모리에 적재하거나 실행이 끝난 프로그램은 메모리에서 삭제된다. 또한 같은 프로그램을 실행하더라도 실행할 때마다 적재되는 주소가 달라진다.

그렇다면 CPU와 실행중인 프로그램이 이해하는 주소는 무엇일까? 주소에는 메모리가 사용하는 **물리 주소**가 존재하고 CPU와 실행 중인 프로그램이 사용하는 **논리 주소**가 있다. 물리 주소는 메모리 입장에서 바라 본 주소로 말 그대로 정보가 실제로 저장된 하드웨어상의 주소를 의미한다. 반면 논리 주소는 CPU와 실행 중인 프로그램 입장에서 바라본 주소를 뜻한다. 보통 실행 중인 프로그램 각각에게 부여되는데 일반적으로 0번지부터 시작하는 주소를 부여한다.

그렇다면 물리 주소와 논리 주소의 변환은 어떻게 이루어질까? 논리 주소와 물리 주소간의 변환은 CPU와 주소 버스 사이에 위치한 메모리 관리 장치(MMU)라는 하드웨어에 의해 수행된다. 그리고 이 MMU는 논리 주소와 베이스 레지스터의 값을 더하여 논리 주소를 물리 주소로 변환해주는 것을 한다.

> 베이스 레지스터: 기준 주소로 프로그램의 물리 시작 주소를 뜻한다.

즉, 이렇게 생각하니 논리 주소는 프로그램 시작 주소에서 얼마나 떨어졌냐를 나타내기도 하는 것 같다.

### 메모리 보호 기법

그러면 만약 CPU가 다른 프로그램의 메모리에 접근하는 명령어를 실행해도 괜찮을까? 모두 알다 싶이 안전하지 못하다. 이것은 바로 **한계 레지스터**를 보고 프로그램의 영역을 침법할 수 있는 명령어의 실행을 막는다. 베이스 레지스터가 실행 중인 프로그램의 가장 작은 물리 주소를 저장한다면 한계 레지스터는 논리 주소의 최대 크기를 저장한다. 즉, CPU가 접근하려는 논리 주소는 한계 레지스터가 저장된 값보다 커서는 안된다.

이처럼 CPU는 메모리에 접근하기 전에 접근하고자 하는 논리주소가 한계 레지스터보다 작은지를 항상 검사한다. 그리고 실행 중인 프로그램의 독립적인 실행 공간을 확보함으로 하나의 프로그램이 다른 프로그램을 침범하지 못하게 하는 것이다.

## 캐시 메모리

CPU는 프로그램을 실행하는 과정에서 메모리에 저장된 데이터를 빈번하게 사용한다. 하지만 CPU가 메모리에 접근하는 시간은 CPU의 연산 속도보다 느리다. 이를 극복하기 위한 저장장치가 바로 **캐시 메모리**이다. 캐시 메모리의 탄생 배경과 특징을 이해하려면 우선 **저장 장치 계층 구조**라는 개념을 이해해야 한다. 그럼 하나씩 알아가보자.

### 저장 장치 계층 구조

모든 사용자들은 빠르고 동시에 용량이 큰 저장 장치를 원한다. 하지만 안타깝게도 빠른 저장 장치와 용량이 큰 저장 장치는 양립하기 어렵다. 저장 장치는 일반적으로 아래와 같은 명제를 따른다.

- CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
- 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

즉, 낮은 가격대의 대용량 저장장치를 원한다면 느린 속도는 감수해야 하고 빠른 메모리를 원한다면 적은 용량과 비싼 가격은 감수해야 한다. 그러면 우리가 지금까지 학습한 저장 장치 계층 구조를 나타내면 속도가 빠른 순으로 아래와 같다.

> 레지스터 -> 메모리 -> 보조 기억 장치

### 캐시 메모리

CPU와 메모리 사이에 위치한 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장장치가 존재하는데 이것이 바로 캐시이다. CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생이 되었다. CPU가 매번 메모리에 왔다 갔다 하는 것은 시간이 오래 걸리니 메모리에서 CPU가 사용 할 일부 데이터를 미리 캐시 메모리로 가져와서 쓴다.

쉽게 비유적으로 표현하면 다음과 같을 것이다. 메모리에 접근한다는 것이 물건을 사러 가는 행위라고 본다면 메모리는 물건은 많지만 집과는 멀리 떨어져 있는 대형마트로 비유를 할 수 있을 것 같고 캐시 메모리는 물건이 많지는 않아도 집과 가까운 편의점을 예시로 들 수 있을 것 같다.

우리가 사용하는 컴퓨터 내부에는 여러개의 캐시 메모리가 존재한다. 그리고 이 캐시 메모리들은 CPU와 가까운 순서대로 계층을 구성한다. 코어와 가장 가까운 캐시 메모리를 L1 캐시, 그 다음 가까운 캐시 메모리를 L2 캐시, 그 다음 가까운 캐시 메모리를 L3 캐시라고 부른다. 또한 멀티 코어 캐시 메모리의 L1, L2 캐시는 서로 다른 내용이 저장될 수 있다. 그럴 경우 동기화 과정도 거쳐야 한다.

> 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치한다.

또한 코어와 가장 가까운 L1 캐시는 조금이라도 접근 속도를 빠르게 만들기 위해 명령어만을 저장하는 L1 캐시인 L1I 캐시와 데이터만을 저장하는 L1 캐시인 L1D 캐시로 분리하는 경우도 있다. 이를 분리형 캐시라고 한다.

### 참조 지역성 원리

캐시 메모리는 메모리보다 용량이 작다. 당연하게도 메모리의 모든 내용을 저장할 수 없다. 그럼 무엇을 저장할까? CPU가 자주 사용할 법한 내용을 예측하여 저장을 한다. 예측이 맞을 경우를 **캐시 히트**라고 하고 예측이 틀릴 경우를 **캐시 미스**라고 한다. 그래서 캐시 메모리의 가장 중요한 것은 캐시 적중률을 높여야 한다. 즉, CPU가 사용할 법한 데이터를 잘 예측해서 참조 지역성의 원리로 가져와야 한다.

여기서 참조 지역성의 원리란 CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리를 말한다. 참조 지역성의 원리란 CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리이다.

- CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다. -> 시간 지역성 ex) 구구단 2단 출력 코드
- CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다. -> 공간 지역성