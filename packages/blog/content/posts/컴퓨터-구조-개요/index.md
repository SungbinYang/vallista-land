---
title: "[컴퓨터 구조] 컴퓨터 구조 개요"
tags:
  - cs
image: ./assets/banner.png
date: 2025-07-18 12:48:27
series: cs
draft: false
---

![배너 이미지](./assets/banner.png)

> 해당 블로그 글은 [감자님의 인프런 강의](https://inf.run/dQpKa)를 바탕으로 쓰여진 글입니다.

## 컴퓨터 구조를 배워야 하는 이유

컴퓨터 구조는 왜 배워야 할까? 일명 명문대라고 일컫는 서울대같은 경우에도 1/2학년에 전공 필수 과목으로 넣은 경우를 많이 보았을 것이다. 아마 뭔가 중요해서 전공 필수로 넣은것일텐데 한번 컴퓨터 구조를 배우면 어떤 이점이 존재하는지 알아보자.

컴퓨터 구조를 배우면 첫째로 **컴퓨터 동작**을 자세히 알 수 있다는 점이다. 컴퓨터는 **트랜지스터**라는 반도체 소자를 이용해 만들 수 있다. 트랜지스터 여러개를 이용해 **NAND 논리 게이트**를 만들 수 있다. 이렇게 컴퓨터 구조 자체를 배우면 이렇게 구성된 각 부품들을 조립해보면서 각 부품들이 어떤 역할을 하는지 이해를 할 수 있을 것이다.

둘째로 **메모리를 이해**할 수 있다는 점이다. 우리가 어떤 프로그래밍 언어로 작성하든지 모든 프로그램은 메모리에 올라와서 동작한다. 우리는 1비트 메모리부터 아주 큰 메모리까지 만들어보고 컴퓨터가 메모리에서 직접 데이터를 가져오도록 하므로 이제는 메모리가 추상적인 개념이 아니게 된다. 그래서 이렇게 만들어보면서 메모리 누수같은 문제가 어떤 치명적인 문제를 발생시키는지 스스로 생각해볼 수 있게 되고 메모리 관리의 중요성에 대해 알게 된다.

세번째로 컴퓨터가 다루는 정보의 기본 단위인 **비트를 자유자재로 사용하는 방법**을 이해하게 된다. 비트는 주로 하드웨어에서 쓰이지만 소프트웨어에서 비트를 활용하여 여러 계산을 할 수 있다. 주로 코딩테스트에서도 많이 이용하여 메모리 최적화등을 이룰 수 있다.

컴퓨터가 실행하는 모든 코드는 0과 1로 이루어진 기계어이다. 우리는 직접 명령어 표를 보면서 기계어 프로그램을 해볼 수 있을텐데 여기서 많은 불편함을 느낄 것이다. 그리고 조금 더 사용자 친화적으로 생산성을 올리고자 어셈블리어를 이용해 프로그래밍을 해보고 어셈블리어가 구조적으로 왜 이렇게 하는지에 대해 알 수 있을 것이다. 그리고 어셈블리어를 조금 더 사용자 친화적으로 생산성을 더 올리고자 고급어가 생겼는데 해당 고급어가 생긴 배경에 대해 알 수 있을 것이다.

컴퓨터 구조를 이해하고 있지 않다면 잘못된 정보를 판단하는 힘이 부족해진다. 컴퓨터 구조를 잘 이해한다면 구조적으로 가능하지 않는 현상을 바로 알아차릴 수 있고 만약 구조의 반환 결과가 나왔다면 원인은 다른 쪽에서 추측할 수 있다는 생각이 들 것이다.

프로그래밍 언어를 이용해 어떻게든 동작하게 하는게 목적이라면 프로그래밍 언어만 배워도 무방하긴 하다. 하지만 이것을 가장 잘하는 것은 AI다. AI가 코드를 만들어내는 속도는 인간이 따라잡기 어렵다. 그래서 요즘 신입 개발자들의 채용을 하지 않고 AI를 보조수단으로 사용하여 개발자의 생산성이 크게 향상되었다. 그러면 어떻게 해야 앞으로 살아남는 개발자가 될 것인가? 주관적인 생각으로는 컴퓨터 과학에 대한 기본 지식을 탄탄히 하여 AI가 생산하는 코드를 단순히 받아 적는 개발자가 아니라 잘못된 것을 판단할 줄 알고 더 효율적이고 문제를 짚어낼 수 있는 개발자가 살아남을 것이다.

> 📚 용어 정리
>
> - 트랜지스터: 전자 회로에서 신호를 증폭하거나 스위치 역할을 하는 반도체 소자
> - NAND 게이트: 디지털 논리 회로에서 사용되는 기본 논리 게이트

## 블랙박스

개발자들은 복잡한 시스템을 더 쉽게 만들고 분석하기 위해 더욱 작은 단위로 쪼갠다. 마치 자동차를 전체를 한번에 만들지 않고 프레임, 바퀴, 휠로 나눠서 만드는 것처럼 말이다. 또 하나의 예시로는 MSA 구조를 생각할 수 있다. 다양한 도메인으로 구성된 프로젝트를 각기 서로 다른 도메인으로 나눠서 해당 부분의 도메인 관련 서버를 만들고 해당 서버 개발에 역할을 맡은 개발자가 해당 부분만 신경쓰는 것처럼 말이다. 그리고 각 서버를 만들고 서로 연결만 해주면 되는 것이다. 연결 담당자는 각 서버의 내부 원리는 몰라도 된다. 단지 각 서버가 정해진 양식대로 잘 만들어졌겠거니 하고 연결만 잘 해주면 되는 것이다. 즉, 연결 담당자는 각 서버가 이런 기능이구나라고만 알아도 서버를 연결해서 MSA 구조를 만들 수 있을 것이다.

이처럼 내부 작동원리는 숨기고 입력에 따른 출력만 예측 가능한 것을 **블랙박스**라고 한다. 이러한 방식으로 복잡한 시스템을 여러 블랙박스로 나누는 것을 **모듈화**라고 한다. 컴퓨터 하드웨어와 소프트웨어 같은 복잡한 시스템을 만들때는 문제를 작은 단위로 나눠서 하나씩 해결해가는 **분할정복방식**을 이용한다. 이는 블랙박스 개념과 모듈화를 통해 이루어진다.

우리는 앞으로 컴퓨터를 만들어가면서 탑 다운 방식으로 설계를 해보고 바텀 업 방식으로 세부 내용을 살펴보도록 하겠다.

> 📚 용어 정리
>
> - 분할 정복: 큰 문제를 보다 작은 문제로 나누어 복잡함을 단순화 하는 것.
> - Top-Down: 위에서 아래로 내려다 보는 방식으로 전체에서 시작해, 점차 세부로 좁혀감.
> - Bottom-Up: 가장 작은 문제부터 답을 구해가면서 전체 문제의 답을 얻는 방식.

## 컴퓨터의 역사

컴퓨터는 이전에 탄생할 때 만들어진 목적은 바로 계산기였다. 그러면 계산기부터 오늘날 컴퓨터가 될 때까지 어떻게 발전을 했는지 한번 알아보자.

인류가 최초로 사용한 컴퓨터는 **주판**이다. 주판으로 계산할 때는 사람이 직접 구슬을 움직여 결과를 얻었기에 수동식 계산기로 분류되었다. 주판은 암산보다 훨씬 빠른 계산이 가능했기에 우리나라에서도 개인용 컴퓨터가 보급되기 전에 주판이 인기였다.

이후, 기원 후 1617년에 **네이피어가 계산봉**을 1642년에는 파스칼이 **파스칼린**을 발명했다. 1673년에는 라이프니츠가 **라이프니츠 휠**을 발명했는데 이는 이후 수많은 탁상용 계산기의 시초가 되었다.

이후, 기계식 계산기에 영감을 받아 1822년에 찰스 배비지가 **차분기관**을 설계하였다. 이는 수 많은 톱니바퀴를 이용하여 이전 계산 결과를 자동으로 활용할 수 있는 진보된 계산기였다. 하지만 당시에 기술적 한계와 예산 부족으로 완성되지는 못했다. 하지만 이를 우회하여 더 혁신적인 계산기인 **해석기관**을 설계했다. 해석기관은 차분기관과 달리 프로그래밍이 가능했고 복잡한 톱니바퀴 구조로 인해 수동 조작이 불가능해 증기기관으로 이용했다. 이는 현대 컴퓨터와 유사한 구조를 가졌지만 기술적 한계와 예산 부족으로 완성되지는 못했다.

기술이 발달하면서 전기를 이용한 전기 계산기가 등장하게 되었다. 1941년에 콜라드 추제는 릴레이 스위치로 구성된 **Z3**를 개발했다. Z3는 세계 최초로 펀치카드를 통해 프로그래밍이 가능한 디지털 계산기였으나 2차 세계 대전 중 폭격으로 파괴되었다. 릴레이는 전기 신호로 기계적 스위치를 동작시켰기 때문에 속도가 제한적이고 부품이 마모되는 단점이 있었다.

1946년 미국 펜실베니아 대학에서 이러한 단점을 해결하고자 진공관을 이용한 **에니악**을 개발했다. 에니악은 진공관 덕에 기계적 마모가 적고 훨씬 빠른 속도를 자랑했다. 그러나 에니악은 펀치카드 대신 전선을 직접 연결하는 방식으로 프로그래밍했어야 했기 때문에 프로그래밍 변경에 많은 인력과 시간이 필요했다. 또한 이런 수 많은 진공관은 작동 중 고장이 많이 발생했다. 이러한 불편함 때문에 프로그래밍 내장방식이 구상되기 시작되었다.

이후 폰 노이만이라는 분이 폰 노이만 컴퓨터를 발표하게 되었고 이는 오늘날 컴퓨터의 주류를 이루게 되었다. **폰 노이만 구조**는 중앙처리장치와 메모리, 입출력 장치를 분리하고 프로그램과 데이터를 모두 메모리에 저장하는 방식이였다. 중앙처리장치에서는 산술 논리연산장치가 계산을 수행하고 제어장치가 모든 동작을 제어한다. 이러한 구조덕분에 개발자들은 전선 연결 대신에 펀치카드로 손쉽게 프로그램을 수정할 수 있게 되었다.

진공관을 대체할 트랜지스터가 발명되면서 컴퓨터의 크기는 더욱 작아지고 속도는 빨라지면서 전력 소모도 크게 줄였다. 이러한 트랜지스터 덕분에 컴퓨터는 2세대로 진입하게 되었다. 1세대 컴퓨터와 동일한 폰 노이만 구조를 유지하면서도 성능은 혁신적으로 향상되었다. 이후 트랜지스터를 더 작은 칩에 정밀하게 직접하는 기술로 직접회로가 개발되면서 컴퓨터는 더욱 빨라지고 소형화되면서 가격도 낮아졌다.

여기서 그치지 않고 직접 회로를 더욱 정밀하게 만드는 기술로 고밀도 직접회로에서 더 정밀한 초고밀도 직접 회로, 그리고 극초고밀도 직접회로롤 발전해오면서 5세대 컴퓨터가 되었다.

## 프로그램은 어떻게 동작할까요?

이번에는 우리가 만든 프로그램이 어떻게 동작하는지 탑-다운 방식을 통해 알아보자. 수 많은 언어들 중에 하나를 이용해 프로그램 개발을 진행할 것이다. 프로그램을 실행하면 컴퓨터는 이를 처리하고 결과를 도출할 것이다. 재밌는 점은 어떤 프로그래밍 언어를 사용하던지 컴퓨터는 문제없이 실행이 가능하다. 그러면 이런 다양한 언어를 컴퓨터는 모두 이해하고 있을까?

사실 컴퓨터는 0과 1로 이루어진 기계어만 이해가 가능하다. 이렇게 0과 1로 이루어진 컴퓨터에게 직접 명령을 내리는 언어를 기계어라고 한다. 하지만 우리가 만든 프로그래밍 언어는 기계어가 아니다. 그럼 우리가 작성한 프로그래밍 언어를 어떻게 컴퓨터가 이해할 수 있을까?

바로 간단하다. 우리가 작성한 프로그래밍 언어가 기계어로 변경되야 할 것이다. 이 변환 작업은 특별한 소프트웨어가 실행을 하는데 크게 두 종류로 나뉜다.

첫째는 컴파일러다. 컴파일러는 우리가 작성한 프로그래밍 언어를 실행 전에 오류가 없는지 혹은 좀 더 최적화는 할 수 없는지 전체적으로 확인을 쭉 한 뒤에 컴퓨터가 이해할 수 있는 언어로 미리 변환한다. 이렇게 변환된 기계어를 실행하면 컴퓨터가 해당 명령을 수행한다.

두번째는 인터프리터이다. 인터프리터는 프로그램을 실행하는 순간부터 코드를 한줄씩 읽어가며 기계어로 변환하고 컴퓨터가 이를 즉시 실행하는 방식이다. 두 방식의 장단점을 살펴보자.

먼저 컴파일 방식의 장점으로는 프로그램을 실행하기 전에 전체 코드를 기계어로 변환하는 과정에서 문법 에러를 미리 발견할 수 있다. 따라서 프로그램 실행 중에 문법 에러가 발생할 수 없다. 또한 전체 코드가 미리 기계어로 변환되기 때문에 실행속도가 매우 빠르다. 이러한 이유로 C/C++ 같은 컴파일 언어는 속도가 중요한 분야에서 많이 쓰인다. 반면 컴파일 방식의 단점은 실행 전 전체 코드를 기계어로 변환하는 과정이 오래 걸린다는 점이 존재한다. 또한 테스트를 위해서 매번 전체 코드를 컴파일해야 하는 번거로운 점도 존재한다.

이제 인터프리터 방식에 대해 살펴보자. 인터프리터 방식의 장점은 프로그램을 한 줄씩 읽어가며 기계어로 변환하기 때문에 코드를 단계별로 확인해가면서 개발할 수 있다는 점이다. 반면 인터프리터 방식의 단점은 실행 중에 한 줄씩 해석하기 때문에 프로그램 실행 도중에 문법 오류가 발생할 수 있다는 점이 존재한다. 또한 실행하면서 기계어로 변환하는 구조이기 때문에 컴파일 언어보다 실행속도 측면에서 느리다.

이러한 속도문제를 개선하기 위해 JIT 컴파일러를 도입하여 자바스크립트, 파이썬등에서 활용하고는 있지만 컴파일 언어보다 빠르게 만들기 어려운 구조적 한계가 존재한다.

이렇게 컴퓨터에 우리가 작성한 프로그램을 실행시키려면 기계어로 변환해야 하는데 여기서 우리가 작성한 사람이 이해하기 쉬원 언어를 고급언어라고 부르며 컴퓨터가 이해하기 쉬운 언어를 저급언어라고 부른다. 고급언어의 대표적인 언어로는 C/C++/Java등이 존재하고 저급언어의 대표적인 언어가 기계어와 어셈블리어가 존재한다.

일반적으로 저급언어에서 고급언어로 갈 수록 코드의 길이가 짧아지며 이에 따라 개발 생산성도 높아진다.

> 잘못된 지식이 있을 경우 댓글로 남겨주시면 빠르게 반영하겠습니다!